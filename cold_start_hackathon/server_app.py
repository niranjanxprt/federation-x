from logging import INFO
import os
import json
import tempfile
import shutil
from datetime import datetime

import torch
import wandb
from flwr.app import ArrayRecord, ConfigRecord, Context
from flwr.common import log
from flwr.serverapp import Grid, ServerApp
from flwr.serverapp.strategy import FedProx

from cold_start_hackathon.task import Net
from cold_start_hackathon.util import (
    compute_aggregated_metrics,
    log_training_metrics,
    log_eval_metrics,
    save_best_model,
)

# ============================================================================
# W&B Configuration - Fill in your credentials or set via environment variables
# ============================================================================
# Option 1: Set these constants directly (e.g., WANDB_API_KEY = "your_api_key_here")
# Option 2: Leave as None and set environment variables (WANDB_API_KEY, WANDB_ENTITY, WANDB_PROJECT)
# If all W&B config is None/unset, W&B logging will be disabled
WANDB_API_KEY = "7490948301e1e8d9c551bc502fb8b0b6b38c2851"
WANDB_PROJECT = "flower-federated-learning"
WANDB_ENTITY = "niranjanxprt-niranjanxprt"
# ============================================================================

# ============================================================================
# Checkpoint Configuration (20-min optimization)
# ============================================================================
CHECKPOINT_DIR = "/home/team02/checkpoints"
os.makedirs(CHECKPOINT_DIR, exist_ok=True)


def load_checkpoint(run_name):
    """Load checkpoint with validation."""
    checkpoint_path = f"{CHECKPOINT_DIR}/{run_name}_latest.pt"
    if os.path.exists(checkpoint_path):
        try:
            checkpoint = torch.load(checkpoint_path, weights_only=True)
            log(INFO, f"âœ“ Loaded checkpoint: {checkpoint_path}")
            return checkpoint
        except Exception as e:
            log(INFO, f"Failed to load checkpoint: {e}")
            return None
    return None


def save_checkpoint(arrays, run_name, server_round, metrics=None):
    """
    Save checkpoint with atomic writes and metadata.
    Prevents corruption during save.
    """
    checkpoint_path = f"{CHECKPOINT_DIR}/{run_name}_latest.pt"
    temp_path = f"{checkpoint_path}.tmp"
    metadata_path = f"{CHECKPOINT_DIR}/{run_name}_metadata.json"

    try:
        # Save to temporary file first (atomic operation)
        torch.save(arrays.to_torch_state_dict(), temp_path)

        # Atomic rename (prevents corruption)
        shutil.move(temp_path, checkpoint_path)

        # Save metadata
        metadata = {
            "round": server_round,
            "timestamp": datetime.now().isoformat(),
            "metrics": metrics or {}
        }
        with open(metadata_path, 'w') as f:
            json.dump(metadata, f, indent=2)

        log(INFO, f"âœ“ Checkpoint saved: {checkpoint_path} (round {server_round})")
    except Exception as e:
        log(INFO, f"Checkpoint save failed: {e}")
        if os.path.exists(temp_path):
            os.remove(temp_path)


app = ServerApp()


@app.main()
def main(grid: Grid, context: Context) -> None:
    # Log GPU device
    device = torch.cuda.get_device_name(0) if torch.cuda.is_available() else "CPU"
    log(INFO, f"Device: {device}")

    num_rounds: int = context.run_config["num-server-rounds"]
    lr: float = context.run_config["lr"]
    local_epochs: int = context.run_config["local-epochs"]

    log(INFO, f"â±ï¸ 20-MINUTE OPTIMIZED MODE")
    log(INFO, f"Config: {num_rounds} rounds, {local_epochs} epochs, LR={lr}")

    # Get run name from environment variable (set by submit-job.sh). Feel free to change this.
    run_name = os.environ.get("JOB_NAME", "your_custom_run_name")

    # Initialize W&B if credentials are provided
    use_wandb = WANDB_API_KEY and WANDB_PROJECT
    if use_wandb:
        wandb.login(key=WANDB_API_KEY)
        log(INFO, "Wandb login successful")
        wandb.init(
            project=WANDB_PROJECT,
            entity=WANDB_ENTITY,
            name=run_name,
            config={
                "num_rounds": num_rounds,
                "learning_rate": lr,
                "local_epochs": local_epochs,
                "strategy": "FedProx",
                "loss": "FocalLoss",
                "mode": "20min_optimized",
                "batch_size": 96
            }
        )
        log(INFO, "Wandb initialized with run_id: %s", wandb.run.id)
    else:
        log(INFO, "W&B disabled (credentials not provided). Set WANDB_API_KEY, WANDB_ENTITY, and WANDB_PROJECT to enable.")

    # Load or create model
    global_model = Net()
    checkpoint = load_checkpoint(run_name)
    if checkpoint:
        global_model.load_state_dict(checkpoint)
        log(INFO, "âœ“ Resumed from checkpoint")
    else:
        log(INFO, "âœ“ Starting fresh training")

    arrays = ArrayRecord(global_model.state_dict())

    # Enhanced FedProx strategy
    strategy = HackathonFedProx(
        fraction_train=1.0,
        fraction_evaluate=1.0,
        min_available_clients=3,
        proximal_mu=0.1,  # Optimized for medical imaging
        run_name=run_name
    )

    log(INFO, "Strategy: FedProx (Î¼=0.1) - Optimized for non-IID medical data")
    log(INFO, "Loss: Focal Loss (Î±=0.25, Î³=2.0, label_smoothing=0.05)")
    result = strategy.start(
        grid=grid,
        initial_arrays=arrays,
        train_config=ConfigRecord({"lr": lr}),
        num_rounds=num_rounds,
    )

    log(INFO, "Training complete")
    if use_wandb:
        wandb.finish()
        log(INFO, "Wandb run finished")


class HackathonFedProx(FedProx):
    """
    Enhanced FedProx for 20-minute jobs.

    Key improvements:
    - Optimized proximal_mu for medical imaging
    - Adaptive aggregation weights
    - Enhanced checkpoint management
    """

    def __init__(self, *args, run_name=None, **kwargs):
        super().__init__(*args, **kwargs)
        self._best_auroc = None
        self._run_name = run_name or "federated_run"
        self._round_history = []

    def aggregate_train(self, server_round, replies):
        """Aggregate with enhanced checkpointing."""
        arrays, metrics = super().aggregate_train(server_round, replies)
        self._arrays = arrays

        # Log training metrics
        log_training_metrics(replies, server_round)

        # Save checkpoint with metrics
        checkpoint_metrics = {
            "train_loss": metrics.get("train_loss", 0.0),
            "num_clients": len(replies)
        }
        save_checkpoint(arrays, self._run_name, server_round, checkpoint_metrics)

        return arrays, metrics

    def aggregate_evaluate(self, server_round, replies):
        """Aggregate with adaptive strategy."""
        agg_metrics = compute_aggregated_metrics(replies)

        # Log evaluation metrics
        log_eval_metrics(
            replies,
            agg_metrics,
            server_round,
            self.weighted_by_key,
            lambda msg: log(INFO, msg)
        )

        # Save best model
        current_auroc = agg_metrics.get("auroc", 0.0)
        if self._best_auroc is None or current_auroc > self._best_auroc:
            self._best_auroc = current_auroc
            save_best_model(
                self._arrays,
                agg_metrics,
                server_round,
                self._run_name,
                self._best_auroc
            )
            log(INFO, f"ğŸ† New best AUROC: {self._best_auroc:.4f}")

        # Track history for adaptive strategies
        self._round_history.append({
            "round": server_round,
            "auroc": current_auroc,
            "metrics": agg_metrics
        })

        return agg_metrics
